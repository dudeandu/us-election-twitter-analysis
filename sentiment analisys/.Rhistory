trump_df$people_mentions <- str_detect(trump_df$full_tweet_text, regex("people", ignore_case = TRUE))
trump_df$women_mentions <- str_detect(trump_df$full_tweet_text, regex("women", ignore_case = TRUE))
# Emotions for each tweet using NRC dictionary
emotions <- get_nrc_sentiment(trump_df$full_tweet_text)
# emotions_syuzhet <- get_sentiment(trump_df$full_tweet_text, method="afinn")
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])
write.csv(emotions, "donald-motions.csv")
# Visualize the emotions from NRC sentiments
library(plotly)
total <- cbind(trump_df, emotions)
colnames(total)
write.csv(total[c(1:4,6:24,69,356:ncol(total))], "trump.csv")
write.csv(total[c(1:4,6:24,75,356:ncol(total))], "trump.csv")
json_file <- "data/biden-tweets.json"
tweets_joeBiden <- fromJSON(paste(readLines(json_file), collapse=""),flatten=TRUE)
biden_df <- as.data.frame(tweets_joeBiden[["results"]])
colnames(biden_df)
nrow(biden_df)
tweet_text <- character()
for (i in 1:nrow(biden_df)) {
if (!is.na(biden_df[i,69])){
# print(biden_df[i,69])
tweet_text <- c(tweet_text, biden_df[i,69])
} else {
# print(biden_df[i,4])
tweet_text <- c(tweet_text, biden_df[i,4])
}
}
biden_df$full_tweet_text <- tweet_text
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
# biden_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("(RT|via)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("@\\w+", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[[:punct:]]", "", biden_df$full_tweet_text)
View(trump_df)
json_file <- "data/trump-tweets.json"
# tweets_realDonaldTrump <- fromJSON(paste(readLines(json_file), collapse=""))
tweets_realDonaldTrump <- fromJSON(paste(readLines(json_file), collapse=""),flatten=TRUE)
trump_df <- as.data.frame(tweets_realDonaldTrump[["results"]])
colnames(trump_df)
nrow(trump_df)
tweet_text <- character()
for (i in 1:nrow(trump_df)) {
if (!is.na(trump_df[i,75])){
# print(trump_df[i,69])
tweet_text <- c(tweet_text, trump_df[i,75])
} else {
# print(trump_df[i,4])
tweet_text <- c(tweet_text, trump_df[i,4])
}
}
trump_df$full_tweet_text <- tweet_text
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
# trump_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("(RT|via)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("@\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:punct:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:digit:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("http\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[ \t]{2,}", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("^\\s+|\\s+$", "", trump_df$full_tweet_text)
trump_df$full_tweet_text <- iconv(trump_df$full_tweet_text, "UTF-8", "ASCII", sub="")
trump_df$joe_mentions <- str_detect(trump_df$full_tweet_text, regex("joe", ignore_case = TRUE))
trump_df$biden_mentions <- str_detect(trump_df$full_tweet_text, regex("biden", ignore_case = TRUE))
trump_df$vote_mentions <- str_detect(trump_df$full_tweet_text, regex("vote", ignore_case = TRUE))
trump_df$america_mentions <- str_detect(trump_df$full_tweet_text, regex("america ", ignore_case = TRUE))
trump_df$country_mentions <- str_detect(trump_df$full_tweet_text, regex("country", ignore_case = TRUE))
trump_df$ballots_mentions <- str_detect(trump_df$full_tweet_text, regex("ballots", ignore_case = TRUE))
trump_df$trump_mentions <- str_detect(trump_df$full_tweet_text, regex("trump", ignore_case = TRUE))
trump_df$republican_mentions <- str_detect(trump_df$full_tweet_text, regex("republican", ignore_case = TRUE))
trump_df$democrat_mentions <- str_detect(trump_df$full_tweet_text, regex("democrat", ignore_case = TRUE))
trump_df$maga_mentions <- str_detect(trump_df$full_tweet_text, regex("maga", ignore_case = TRUE))
trump_df$canada_mentions <- str_detect(trump_df$full_tweet_text, regex("canada", ignore_case = TRUE))
trump_df$black_mentions <- str_detect(trump_df$full_tweet_text, regex("black", ignore_case = TRUE))
trump_df$industry_mentions <- str_detect(trump_df$full_tweet_text, regex("industry", ignore_case = TRUE))
trump_df$hispanic_mentions <- str_detect(trump_df$full_tweet_text, regex("hispanic", ignore_case = TRUE))
trump_df$elections_mentions <- str_detect(trump_df$full_tweet_text, regex("elections", ignore_case = TRUE))
trump_df$covid_mentions <- str_detect(trump_df$full_tweet_text, regex("covid", ignore_case = TRUE))
trump_df$virus_mentions <- str_detect(trump_df$full_tweet_text, regex("virus", ignore_case = TRUE))
trump_df$healthcare_mentions <- str_detect(trump_df$full_tweet_text, regex("healthcare", ignore_case = TRUE))
trump_df$health_mentions <- str_detect(trump_df$full_tweet_text, regex("health", ignore_case = TRUE))
trump_df$people_mentions <- str_detect(trump_df$full_tweet_text, regex("people", ignore_case = TRUE))
trump_df$women_mentions <- str_detect(trump_df$full_tweet_text, regex("women", ignore_case = TRUE))
# Emotions for each tweet using NRC dictionary
emotions <- get_nrc_sentiment(trump_df$full_tweet_text)
# emotions_syuzhet <- get_sentiment(trump_df$full_tweet_text, method="afinn")
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])
write.csv(emotions, "donald-motions.csv")
# Visualize the emotions from NRC sentiments
library(plotly)
total <- cbind(trump_df, emotions)
colnames(total)
write.csv(total[c(1:4,6:24,75,356:ncol(total))], "trump.csv")
json_file <- "data/biden-tweets.json"
tweets_joeBiden <- fromJSON(paste(readLines(json_file), collapse=""),flatten=TRUE)
biden_df <- as.data.frame(tweets_joeBiden[["results"]])
colnames(biden_df)
nrow(biden_df)
tweet_text <- character()
for (i in 1:nrow(biden_df)) {
if (!is.na(biden_df[i,69])){
# print(biden_df[i,69])
tweet_text <- c(tweet_text, biden_df[i,69])
} else {
# print(biden_df[i,4])
tweet_text <- c(tweet_text, biden_df[i,4])
}
}
biden_df$full_tweet_text <- tweet_text
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
# biden_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("(RT|via)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("@\\w+", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[[:punct:]]", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[[:digit:]]", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("http\\w+", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[ \t]{2,}", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("^\\s+|\\s+$", "", biden_df$full_tweet_text)
biden_df$full_tweet_text <- iconv(biden_df$full_tweet_text, "UTF-8", "ASCII", sub="")
### just in case
biden_df$full_tweet_text <- gsub("http\\s+","",biden_df$full_tweet_text)
biden_df$joe_mentions <- str_detect(biden_df$full_tweet_text, regex("joe", ignore_case = TRUE))
biden_df$biden_mentions <- str_detect(biden_df$full_tweet_text, regex("biden", ignore_case = TRUE))
biden_df$vote_mentions <- str_detect(biden_df$full_tweet_text, regex("vote", ignore_case = TRUE))
biden_df$america_mentions <- str_detect(biden_df$full_tweet_text, regex("america ", ignore_case = TRUE))
biden_df$country_mentions <- str_detect(biden_df$full_tweet_text, regex("country", ignore_case = TRUE))
biden_df$ballots_mentions <- str_detect(biden_df$full_tweet_text, regex("ballots", ignore_case = TRUE))
biden_df$trump_mentions <- str_detect(biden_df$full_tweet_text, regex("trump", ignore_case = TRUE))
biden_df$republican_mentions <- str_detect(biden_df$full_tweet_text, regex("republican", ignore_case = TRUE))
biden_df$democrat_mentions <- str_detect(biden_df$full_tweet_text, regex("democrat", ignore_case = TRUE))
biden_df$maga_mentions <- str_detect(biden_df$full_tweet_text, regex("maga", ignore_case = TRUE))
biden_df$canada_mentions <- str_detect(biden_df$full_tweet_text, regex("canada", ignore_case = TRUE))
biden_df$black_mentions <- str_detect(biden_df$full_tweet_text, regex("black", ignore_case = TRUE))
biden_df$industry_mentions <- str_detect(biden_df$full_tweet_text, regex("industry", ignore_case = TRUE))
biden_df$hispanic_mentions <- str_detect(biden_df$full_tweet_text, regex("hispanic", ignore_case = TRUE))
biden_df$elections_mentions <- str_detect(biden_df$full_tweet_text, regex("elections", ignore_case = TRUE))
biden_df$covid_mentions <- str_detect(biden_df$full_tweet_text, regex("covid", ignore_case = TRUE))
biden_df$virus_mentions <- str_detect(biden_df$full_tweet_text, regex("virus", ignore_case = TRUE))
biden_df$healthcare_mentions <- str_detect(biden_df$full_tweet_text, regex("healthcare", ignore_case = TRUE))
biden_df$health_mentions <- str_detect(biden_df$full_tweet_text, regex("health", ignore_case = TRUE))
biden_df$people_mentions <- str_detect(biden_df$full_tweet_text, regex("people", ignore_case = TRUE))
biden_df$women_mentions <- str_detect(biden_df$full_tweet_text, regex("women", ignore_case = TRUE))
# Emotions for each tweet using NRC dictionary
emotions <- get_nrc_sentiment(biden_df$full_tweet_text)
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])
write.csv(emotions, "joe-motions.csv")
# Visualize the emotions from NRC sentiments
library(plotly)
total <- cbind(biden_df, emotions)
colnames(total)
write.csv(total[c(1:4,6:24,69,324:ncol(total))], "biden.csv")
write.csv(total[c(1:4,6:24,69,246:ncol(total))], "biden.csv")
trump_df$full_tweet_text =gsub("&amp", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
# trump_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("(RT|via)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("@\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:punct:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:digit:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("http\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[ \t]{2,}", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("^\\s+|\\s+$", "", trump_df$full_tweet_text)
trump_df$full_tweet_text <- iconv(trump_df$full_tweet_text, "UTF-8", "ASCII", sub="")
### just in case
trump_df$stripped <- gsub("http\\s+","",trump_df$full_tweet_text)
### Get the canon
trump_df_stem <- trump_df %>%
select(stripped) %>%
unnest_tokens(word, stripped)
head(trump_df_stem)
## remove stop words
cleaned_trump_df <- trump_df_stem %>%
anti_join(stop_words)
write.csv(cleaned_trump_df, "donald-canon.csv")
head(cleaned_trump_df)
### Top 10 words in @realDonaldTrump
cleaned_trump_df %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_classic() +
labs(x = "Count",
y = "Unique words",
title = "Unique word count in @realDonaldTrump tweets")
book_words <- trump_df %>%
unnest_tokens(word, full_tweet_text) %>%
count(word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
require(rjson)
require(jsonlite)
require(data.table)
require(twitteR)
require(RCurl)
require(httr)
require(ggplot2)
require(base64enc)
require(tm)
require(wordcloud)
require(syuzhet)
require(dplyr)
require(tidyr)
require(tidytext)
### Top 10 words in @realDonaldTrump
cleaned_trump_df %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_classic() +
labs(x = "Count",
y = "Unique words",
title = "Unique word count in @realDonaldTrump tweets")
book_words <- trump_df %>%
unnest_tokens(word, full_tweet_text) %>%
count(word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
### Get the canon
biden_df_stem <- biden_df %>%
select(stripped) %>%
unnest_tokens(word, stripped)
### just in case
biden_df$stripped <- gsub("http\\s+","",biden_df$full_tweet_text)
### Get the canon
biden_df_stem <- biden_df %>%
select(stripped) %>%
unnest_tokens(word, stripped)
head(biden_df_stem)
## remove stop words
cleaned_biden_df <- biden_df_stem %>%
anti_join(stop_words)
head(cleaned_biden_df)
### Top 10 words in @JoeBiden
cleaned_biden_df %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_classic() +
labs(x = "Count",
y = "Unique words",
title = "Unique word cont in @JoeBiden tweets")
book_words <- biden_df %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words
write.csv(book_words, "biden-allword-count.csv")
bidentop20 <- cleaned_biden_df %>%
count(word, sort = TRUE) %>%
# top_n(20) %>%
mutate(word = reorder(word, n))
write.csv(bidentop20, "biden-word-count.csv")
book_words
write.csv(book_words, "donald-allword-count.csv")
trumptop20 <- cleaned_trump_df %>%
count(word, sort = TRUE) %>%
# top_n(20) %>%
mutate(word = reorder(word, n))
write.csv(trumptop20, "donald-word-count.csv")
json_file <- "data/trump-tweets.json"
# tweets_realDonaldTrump <- fromJSON(paste(readLines(json_file), collapse=""))
tweets_realDonaldTrump <- fromJSON(paste(readLines(json_file), collapse=""),flatten=TRUE)
trump_df <- as.data.frame(tweets_realDonaldTrump[["results"]])
colnames(trump_df)
nrow(trump_df)
tweet_text <- character()
for (i in 1:nrow(trump_df)) {
if (!is.na(trump_df[i,75])){
# print(trump_df[i,69])
tweet_text <- c(tweet_text, trump_df[i,75])
} else {
# print(trump_df[i,4])
tweet_text <- c(tweet_text, trump_df[i,4])
}
}
trump_df$full_tweet_text <- tweet_text
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
# trump_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("(RT|via)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("@\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:punct:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:digit:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("http\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[ \t]{2,}", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("^\\s+|\\s+$", "", trump_df$full_tweet_text)
trump_df$full_tweet_text <- iconv(trump_df$full_tweet_text, "UTF-8", "ASCII", sub="")
trump_df$joe_mentions <- str_detect(trump_df$full_tweet_text, regex("joe", ignore_case = TRUE))
trump_df$biden_mentions <- str_detect(trump_df$full_tweet_text, regex("biden", ignore_case = TRUE))
trump_df$vote_mentions <- str_detect(trump_df$full_tweet_text, regex("vote", ignore_case = TRUE))
trump_df$america_mentions <- str_detect(trump_df$full_tweet_text, regex("america ", ignore_case = TRUE))
trump_df$country_mentions <- str_detect(trump_df$full_tweet_text, regex("country", ignore_case = TRUE))
trump_df$ballots_mentions <- str_detect(trump_df$full_tweet_text, regex("ballots", ignore_case = TRUE))
trump_df$trump_mentions <- str_detect(trump_df$full_tweet_text, regex("trump", ignore_case = TRUE))
trump_df$republican_mentions <- str_detect(trump_df$full_tweet_text, regex("republican", ignore_case = TRUE))
trump_df$democrat_mentions <- str_detect(trump_df$full_tweet_text, regex("democrat", ignore_case = TRUE))
trump_df$maga_mentions <- str_detect(trump_df$full_tweet_text, regex("maga", ignore_case = TRUE))
trump_df$canada_mentions <- str_detect(trump_df$full_tweet_text, regex("canada", ignore_case = TRUE))
trump_df$black_mentions <- str_detect(trump_df$full_tweet_text, regex("black", ignore_case = TRUE))
trump_df$industry_mentions <- str_detect(trump_df$full_tweet_text, regex("industry", ignore_case = TRUE))
trump_df$hispanic_mentions <- str_detect(trump_df$full_tweet_text, regex("hispanic", ignore_case = TRUE))
trump_df$elections_mentions <- str_detect(trump_df$full_tweet_text, regex("elections", ignore_case = TRUE))
trump_df$covid_mentions <- str_detect(trump_df$full_tweet_text, regex("covid", ignore_case = TRUE))
trump_df$virus_mentions <- str_detect(trump_df$full_tweet_text, regex("virus", ignore_case = TRUE))
trump_df$healthcare_mentions <- str_detect(trump_df$full_tweet_text, regex("healthcare", ignore_case = TRUE))
trump_df$health_mentions <- str_detect(trump_df$full_tweet_text, regex("health", ignore_case = TRUE))
trump_df$people_mentions <- str_detect(trump_df$full_tweet_text, regex("people", ignore_case = TRUE))
trump_df$women_mentions <- str_detect(trump_df$full_tweet_text, regex("women", ignore_case = TRUE))
# Emotions for each tweet using NRC dictionary
emotions <- get_nrc_sentiment(trump_df$full_tweet_text)
# emotions_syuzhet <- get_sentiment(trump_df$full_tweet_text, method="afinn")
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])
write.csv(emotions, "donald-motions.csv")
# Visualize the emotions from NRC sentiments
library(plotly)
plot_ly(emo_sum, x=~emotion, y=~count, type="bar", color=~emotion) %>%
layout(xaxis=list(title=""), showlegend=FALSE, title="Emotion Type: @realDonaldTrump")
total <- cbind(trump_df, emotions)
colnames(total)
write.csv(total[c(1:4,6:24,75,356:ncol(total))], "trump.csv")
trump_df$full_tweet_text =gsub("&amp", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("&amp", "", trump_df$full_tweet_text)
# trump_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("(RT|via)", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("@\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:punct:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[[:digit:]]", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("http\\w+", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("[ \t]{2,}", "", trump_df$full_tweet_text)
trump_df$full_tweet_text = gsub("^\\s+|\\s+$", "", trump_df$full_tweet_text)
trump_df$full_tweet_text <- iconv(trump_df$full_tweet_text, "UTF-8", "ASCII", sub="")
### just in case
trump_df$stripped <- gsub("http\\s+","",trump_df$full_tweet_text)
### Get the canon
trump_df_stem <- trump_df %>%
select(stripped) %>%
unnest_tokens(word, stripped)
head(trump_df_stem)
## remove stop words
cleaned_trump_df <- trump_df_stem %>%
anti_join(stop_words)
write.csv(cleaned_trump_df, "donald-canon.csv")
head(cleaned_trump_df)
### Top 10 words in @realDonaldTrump
cleaned_trump_df %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_classic() +
labs(x = "Count",
y = "Unique words",
title = "Unique word count in @realDonaldTrump tweets")
book_words <- trump_df %>%
unnest_tokens(word, full_tweet_text) %>%
count(word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words
write.csv(book_words, "donald-allword-count.csv")
trumptop20 <- cleaned_trump_df %>%
count(word, sort = TRUE) %>%
# top_n(20) %>%
mutate(word = reorder(word, n))
write.csv(trumptop20, "donald-word-count.csv")
json_file <- "data/biden-tweets.json"
tweets_joeBiden <- fromJSON(paste(readLines(json_file), collapse=""),flatten=TRUE)
biden_df <- as.data.frame(tweets_joeBiden[["results"]])
colnames(biden_df)
nrow(biden_df)
tweet_text <- character()
for (i in 1:nrow(biden_df)) {
if (!is.na(biden_df[i,69])){
# print(biden_df[i,69])
tweet_text <- c(tweet_text, biden_df[i,69])
} else {
# print(biden_df[i,4])
tweet_text <- c(tweet_text, biden_df[i,4])
}
}
biden_df$full_tweet_text <- tweet_text
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("&amp", "", biden_df$full_tweet_text)
# biden_df$full_tweet_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("(RT|via)", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("@\\w+", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[[:punct:]]", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[[:digit:]]", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("http\\w+", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("[ \t]{2,}", "", biden_df$full_tweet_text)
biden_df$full_tweet_text = gsub("^\\s+|\\s+$", "", biden_df$full_tweet_text)
biden_df$full_tweet_text <- iconv(biden_df$full_tweet_text, "UTF-8", "ASCII", sub="")
### just in case
biden_df$full_tweet_text <- gsub("http\\s+","",biden_df$full_tweet_text)
biden_df$joe_mentions <- str_detect(biden_df$full_tweet_text, regex("joe", ignore_case = TRUE))
biden_df$biden_mentions <- str_detect(biden_df$full_tweet_text, regex("biden", ignore_case = TRUE))
biden_df$vote_mentions <- str_detect(biden_df$full_tweet_text, regex("vote", ignore_case = TRUE))
biden_df$america_mentions <- str_detect(biden_df$full_tweet_text, regex("america ", ignore_case = TRUE))
biden_df$country_mentions <- str_detect(biden_df$full_tweet_text, regex("country", ignore_case = TRUE))
biden_df$ballots_mentions <- str_detect(biden_df$full_tweet_text, regex("ballots", ignore_case = TRUE))
biden_df$trump_mentions <- str_detect(biden_df$full_tweet_text, regex("trump", ignore_case = TRUE))
biden_df$republican_mentions <- str_detect(biden_df$full_tweet_text, regex("republican", ignore_case = TRUE))
biden_df$democrat_mentions <- str_detect(biden_df$full_tweet_text, regex("democrat", ignore_case = TRUE))
biden_df$maga_mentions <- str_detect(biden_df$full_tweet_text, regex("maga", ignore_case = TRUE))
biden_df$canada_mentions <- str_detect(biden_df$full_tweet_text, regex("canada", ignore_case = TRUE))
biden_df$black_mentions <- str_detect(biden_df$full_tweet_text, regex("black", ignore_case = TRUE))
biden_df$industry_mentions <- str_detect(biden_df$full_tweet_text, regex("industry", ignore_case = TRUE))
biden_df$hispanic_mentions <- str_detect(biden_df$full_tweet_text, regex("hispanic", ignore_case = TRUE))
biden_df$elections_mentions <- str_detect(biden_df$full_tweet_text, regex("elections", ignore_case = TRUE))
biden_df$covid_mentions <- str_detect(biden_df$full_tweet_text, regex("covid", ignore_case = TRUE))
biden_df$virus_mentions <- str_detect(biden_df$full_tweet_text, regex("virus", ignore_case = TRUE))
biden_df$healthcare_mentions <- str_detect(biden_df$full_tweet_text, regex("healthcare", ignore_case = TRUE))
biden_df$health_mentions <- str_detect(biden_df$full_tweet_text, regex("health", ignore_case = TRUE))
biden_df$people_mentions <- str_detect(biden_df$full_tweet_text, regex("people", ignore_case = TRUE))
biden_df$women_mentions <- str_detect(biden_df$full_tweet_text, regex("women", ignore_case = TRUE))
# Emotions for each tweet using NRC dictionary
emotions <- get_nrc_sentiment(biden_df$full_tweet_text)
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])
write.csv(emotions, "joe-motions.csv")
# Visualize the emotions from NRC sentiments
library(plotly)
plot_ly(emo_sum, x=~emotion, y=~count, type="bar", color=~emotion) %>%
layout(xaxis=list(title=""), showlegend=FALSE, title="Emotion Type: @joeBiden")
total <- cbind(biden_df, emotions)
colnames(total)
write.csv(total[c(1:4,6:24,69,246:ncol(total))], "biden.csv")
write.csv(total[c(1:4,6:24,69,326:ncol(total))], "biden.csv")
biden_df$text = gsub("&amp", "", biden_df$text)
# biden_df$text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", biden_df$text)
biden_df$text = gsub("(RT|via)", "", biden_df$text)
biden_df$text = gsub("@\\w+", "", biden_df$text)
biden_df$text = gsub("[[:punct:]]", "", biden_df$text)
biden_df$text = gsub("[[:digit:]]", "", biden_df$text)
biden_df$text = gsub("http\\w+", "", biden_df$text)
biden_df$text = gsub("[ \t]{2,}", "", biden_df$text)
biden_df$text = gsub("^\\s+|\\s+$", "", biden_df$text)
biden_df$text <- iconv(biden_df$text, "UTF-8", "ASCII", sub="")
### just in case
biden_df$stripped <- gsub("http\\s+","",biden_df$full_tweet_text)
### Get the canon
biden_df_stem <- biden_df %>%
select(stripped) %>%
unnest_tokens(word, stripped)
head(biden_df_stem)
## remove stop words
cleaned_biden_df <- biden_df_stem %>%
anti_join(stop_words)
head(cleaned_biden_df)
### Top 10 words in @JoeBiden
cleaned_biden_df %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_classic() +
labs(x = "Count",
y = "Unique words",
title = "Unique word cont in @JoeBiden tweets")
book_words <- biden_df %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words
write.csv(book_words, "biden-allword-count.csv")
bidentop20 <- cleaned_biden_df %>%
count(word, sort = TRUE) %>%
# top_n(20) %>%
mutate(word = reorder(word, n))
write.csv(bidentop20, "biden-word-count.csv")
